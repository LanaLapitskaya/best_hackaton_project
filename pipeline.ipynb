{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The class provides basic functionality for retrieving\n",
    "    a subset of columns from the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names):\n",
    "        \"\"\"\n",
    "        Initialize class instance by setting\n",
    "        a list of columns to retrieve from the dataset.\n",
    "        \"\"\"\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit FeatureSelector to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform X using feature selection. \n",
    "        Return column-subset of X.\n",
    "        \"\"\"\n",
    "        return X[self.feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Required columns: table. X is DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {\n",
    "             'ABS (антиблокировочная система)',\n",
    "             'AUX/iPod',\n",
    "             'Bluetooth',\n",
    "             'CD/MP3 проигрыватель',\n",
    "             'ESP (система поддержания динамической стабильности)',\n",
    "             'USB',\n",
    "             'Автозапуск двигателя',\n",
    "             'Антипробуксовочная система',\n",
    "             'Датчик дождя',\n",
    "             'Иммобилайзер',\n",
    "             'Камера заднего вида',\n",
    "             'Климат-контроль',\n",
    "             'Кондиционер',\n",
    "             'Контроль мертвых зон на зеркалах',\n",
    "             'Круиз-контроль',\n",
    "             'Ксеноновые фары',\n",
    "             'Легкосплавные диски',\n",
    "             'Люк',\n",
    "             'Материал салона - натуральная кожа',\n",
    "             'Мультимедийный экран',\n",
    "             'Обогрев зеркал',\n",
    "             'Обогрев лобового стекла',\n",
    "             'Обогрев руля',\n",
    "             'Обогрев сидений',\n",
    "             'Панорамная крыша',\n",
    "             'Парктроники',\n",
    "             'Подушки безопасности боковые',\n",
    "             'Подушки безопасности задние',\n",
    "             'Подушки безопасности передние',\n",
    "             'Противотуманные фары',\n",
    "             'Рейлинги на крыше',\n",
    "             'Светодиодные фары',\n",
    "             'Сигнализация',\n",
    "             'Системы помощи',\n",
    "             'Управление мультимедиа с руля',\n",
    "             'Фаркоп',\n",
    "             'Штатная навигация',\n",
    "             'Электрорегулировка сидений',\n",
    "             'Электростеклоподъемники задние',\n",
    "             'Электростеклоподъемники передние'}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.add_features(X)\n",
    "        return X[self.features].values\n",
    "    \n",
    "    def add_features(self, X):\n",
    "        for imp in self.features:\n",
    "            X[imp] = X.table.apply(lambda x: int(imp in x)).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToIntTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Required columns: volume, show, run, pages, update, year.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        # self.to_int(X, 'cost', ' ')\n",
    "        self.to_int(X, 'volume', ' см3')\n",
    "        self.fix_show(X)\n",
    "        self.fix_run(X)\n",
    "        self.fix_dates(X)\n",
    "        self.add_restyle(X)\n",
    "        self.add_upd_flags(X)\n",
    "        self.year_to_old(X)\n",
    "        return X.drop(['model', 'update', 'pages', 'year'], axis=1).values\n",
    "    \n",
    "    def to_int(self, X, column_name, phrase):\n",
    "        X[column_name] = X[column_name].str.replace(phrase, '').astype('int32')\n",
    "        \n",
    "    def year_to_old(self, X):\n",
    "        X['age'] = (2019 - X['year']).astype('int8')\n",
    "        \n",
    "    def fix_show(self, X):\n",
    "        X['today_views'] = X['show'].str.extract('\\+(.+) ')\n",
    "        X['show'] = X['show'].str.extract('(.*)' + ' '*25)\n",
    "        X.rename(columns={'show': 'all_views'}, inplace=True)\n",
    "        today_view_mask = pd.isna(X['today_views'])\n",
    "        X.loc[today_view_mask, 'today_views'] = X[today_view_mask]['all_views']\n",
    "        X['today_views'] = X['today_views'].astype('int')\n",
    "        X['all_views'] = X['all_views'].astype('int')\n",
    "        \n",
    "    def fix_run(self, X):\n",
    "        X['run'] = X['run'].str.replace(' км', '')\n",
    "        miles_mask = X['run'].str.endswith(' миль')\n",
    "        X.loc[miles_mask, 'run'] = X[miles_mask]['run'].str.replace(' миль', '').astype('int') * 1.60934\n",
    "        X['run'] = X['run'].astype('int')\n",
    "        \n",
    "    def add_restyle(self, X):\n",
    "        self.create_model(X)\n",
    "        X['is_restyle'] = X['model'].str.endswith('(рестайлинг)').astype('int8')\n",
    "        \n",
    "    def add_upd_flags(self, X):\n",
    "        X['modified'] = X['update'].apply(\n",
    "            lambda x: int(not x.split()[0] == 'Опубликовано')).astype('int8')\n",
    "        X['up'] = X['update'].apply(\n",
    "            lambda x: int(len(x.split()) == 4)).astype('int8')\n",
    "    \n",
    "    def create_model(self, X):\n",
    "        two_word_names = ('Alfa Romeo', 'Great Wall', 'Lada (ВАЗ)')\n",
    "        two_word_names_mask = X['pages'].str.startswith(two_word_names)\n",
    "        X.loc[two_word_names_mask, 'model'] = (X[two_word_names_mask]['pages'].str.split()\n",
    "                                                .apply(lambda name: ' '.join(name[2:])))\n",
    "        X.loc[~two_word_names_mask, 'model'] = (X[~two_word_names_mask]['pages'].str.split()\n",
    "                                                 .apply(lambda name: ' '.join(name[1:])))\n",
    "    \n",
    "    def fix_dates(self, df):\n",
    "        today=pd.Timestamp(2019, 11, 23)\n",
    "        df['days_ago'] = df['update'].apply(\n",
    "            lambda x: (today - pd.Timestamp(x.split()[1])).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Required columns: cuzov, fuel, pages, region, update.\n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.preserve = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        two_word_names = ('Alfa Romeo', 'Great Wall', 'Lada (ВАЗ)')\n",
    "        two_word_names_mask = X['pages'].str.startswith(two_word_names)\n",
    "        X.loc[two_word_names_mask, 'pages'] = (X[two_word_names_mask]['pages'].str.split()\n",
    "                                                .apply(lambda name: ' '.join(name[:2])))\n",
    "        X.loc[~two_word_names_mask, 'pages'] = (X[~two_word_names_mask]['pages'].str.split()\n",
    "                                                 .apply(lambda name: ' '.join(name[:1])))\n",
    "        vc = X.pages.value_counts() / len(X)\n",
    "        self.preserve = vc[vc > 0.01]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.cut(X, ['cuzov', 'fuel'])\n",
    "        self.fix_names(X)\n",
    "        self.fix_region(X)\n",
    "        return X.drop(['update'], axis=1).values\n",
    "    \n",
    "    def cut(self, X, column_names):\n",
    "        for col in column_names:\n",
    "            X[col] = X[col].apply(lambda x: x.split()[0])\n",
    "        \n",
    "    def fix_names(self, df):\n",
    "        two_word_names = ('Alfa Romeo', 'Great Wall', 'Lada (ВАЗ)')\n",
    "        two_word_names_mask = df['pages'].str.startswith(two_word_names)\n",
    "        df.loc[two_word_names_mask, 'pages'] = (df[two_word_names_mask]['pages'].str.split()\n",
    "                                                .apply(lambda name: ' '.join(name[:2])))\n",
    "        df.loc[~two_word_names_mask, 'pages'] = (df[~two_word_names_mask]['pages'].str.split()\n",
    "                                                 .apply(lambda name: ' '.join(name[:1])))\n",
    "        df.rename(columns={'pages': 'brand'}, inplace=True)\n",
    "        vc = df.brand.value_counts() / len(df)\n",
    "        df.brand = df.brand.apply(lambda x: x if x in self.preserve else 'other')\n",
    "        \n",
    "    def fix_region(self, X):\n",
    "        \n",
    "        def _get_region(lst):\n",
    "            if len(lst) == 1:\n",
    "                return lst[0]\n",
    "            return lst[1]\n",
    "        \n",
    "        tmp = list(map(lambda s: s.split(', '), X.region))\n",
    "        X.region = list(map(_get_region, tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnTranslation:\n",
    "    \n",
    "    def __init__(self, column_name, to_save, default='Other'):\n",
    "        self.column_name = column_name\n",
    "        self.to_save = to_save\n",
    "        self.default = default\n",
    "\n",
    "\n",
    "class Translator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, translations):\n",
    "        self.translations = translations[:]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for tr in self.translations:\n",
    "            X[tr.column_name] = X[tr.column_name].apply(\n",
    "                lambda x: x if x in tr.to_save else tr.default)\n",
    "        return X[[tr.column_name for tr in self.translations]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "avto = pd.read_csv('dataset/final.csv')\n",
    "\n",
    "X = avto.drop(['cost'], axis=1)\n",
    "y = avto.cost.apply(lambda x: int(x.replace(' ', '')))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=42)\n",
    "\n",
    "feat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('feat_selector', FeatureSelector(['table'])),\n",
    "        ('feat_generator', FeatureGenerator())\n",
    "    ]\n",
    ")\n",
    "\n",
    "int_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('int_selector', FeatureSelector(['volume', 'show', 'run', 'pages', 'update', 'year'])),\n",
    "        ('int_transformer', ToIntTransformer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('cat_selector', FeatureSelector(['cuzov', 'fuel', 'pages', 'region', 'update'])),\n",
    "        ('cat_transformer', CatTransformer()),\n",
    "        ('cat_encoder', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "color_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('color_selector', FeatureSelector(['color'])),\n",
    "        ('color_translator', Translator(\n",
    "            [ColumnTranslation(\n",
    "                column_name='color',\n",
    "                to_save=['черный', 'серебристый', 'синий', 'серый', 'белый'],\n",
    "                default='другой'\n",
    "            )])),\n",
    "        ('color_encoder', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "no_proc_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('no_proc_selector', FeatureSelector(['drive-unit', 'state', 'transmission'])),\n",
    "        ('no_proc_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('no_proc_encoder', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = FeatureUnion(transformer_list= [\n",
    "    ('feat', feat_pipeline),\n",
    "    ('int', int_pipeline),\n",
    "    ('cat', cat_pipeline),\n",
    "    ('color', color_pipeline),\n",
    "    ('no_proc', no_proc_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8520849040443894\n"
     ]
    }
   ],
   "source": [
    "xg_params = [\n",
    "    {\n",
    "        'max_depth': [3, 5, 7, 9, 11],\n",
    "        'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200],\n",
    "        'gamma': [0.1, 0.25],\n",
    "    }\n",
    "]\n",
    "\n",
    "pip = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessing', pipeline),\n",
    "        ('gc', GridSearchCV(xg.XGBRegressor(\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            objective='reg:squarederror'\n",
    "        ), xg_params, scoring='r2', refit=True, n_jobs=-1, cv=5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pip.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, pip.predict(X_test)\n",
    "print(metrics.r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8640 out of 8640 | elapsed: 35.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8628926435911706\n"
     ]
    }
   ],
   "source": [
    "lgb_params = [\n",
    "    {\n",
    "        'boosting_type': ['gbdt', 'goss'],\n",
    "        'num_leaves': [50, 73, 100, 120, 150, 160, 180, 230, 255],\n",
    "        'max_depth': [5, 7, 9, 11],\n",
    "        'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.15, 0.2],\n",
    "        'n_estimators': [100, 150, 200, 250],\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "pip = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessing', pipeline),\n",
    "        ('gc', GridSearchCV(lgb.LGBMRegressor(random_state=42),\n",
    "                            lgb_params, scoring='r2', n_jobs=-1, \n",
    "                            cv=5, refit=True, verbose=5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pip.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, pip.predict(X_test)\n",
    "print(metrics.r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 11,\n",
       " 'n_estimators': 250,\n",
       " 'num_leaves': 50}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip['gc'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
